{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ab5770",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc7a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://vsikatalogi.si/akcije/page/1\n",
      "Scraping https://vsikatalogi.si/akcije/page/2\n",
      "Scraping https://vsikatalogi.si/akcije/page/3\n",
      "Scraping https://vsikatalogi.si/akcije/page/4\n",
      "Scraping https://vsikatalogi.si/akcije/page/5\n",
      "Scraping https://vsikatalogi.si/akcije/page/6\n",
      "Scraping https://vsikatalogi.si/akcije/page/7\n",
      "Scraping https://vsikatalogi.si/akcije/page/8\n",
      "Scraping https://vsikatalogi.si/akcije/page/9\n",
      "Scraping https://vsikatalogi.si/akcije/page/10\n",
      "Scraping https://vsikatalogi.si/akcije/page/11\n",
      "Scraping https://vsikatalogi.si/akcije/page/12\n",
      "Scraping https://vsikatalogi.si/akcije/page/13\n",
      "Scraping https://vsikatalogi.si/akcije/page/14\n",
      "Scraping https://vsikatalogi.si/akcije/page/15\n",
      "Scraping https://vsikatalogi.si/akcije/page/16\n",
      "Scraping https://vsikatalogi.si/akcije/page/17\n",
      "Scraping https://vsikatalogi.si/akcije/page/18\n",
      "Scraping https://vsikatalogi.si/akcije/page/19\n",
      "Scraping https://vsikatalogi.si/akcije/page/20\n",
      "Scraping https://vsikatalogi.si/akcije/page/21\n",
      "Scraping https://vsikatalogi.si/akcije/page/22\n",
      "Scraping https://vsikatalogi.si/akcije/page/23\n",
      "Scraping https://vsikatalogi.si/akcije/page/24\n",
      "Scraping https://vsikatalogi.si/akcije/page/25\n",
      "Scraping https://vsikatalogi.si/akcije/page/26\n",
      "Scraping https://vsikatalogi.si/akcije/page/27\n",
      "Scraping https://vsikatalogi.si/akcije/page/28\n",
      "Scraping https://vsikatalogi.si/akcije/page/29\n",
      "Scraping https://vsikatalogi.si/akcije/page/30\n",
      "Scraping https://vsikatalogi.si/akcije/page/31\n",
      "Scraping https://vsikatalogi.si/akcije/page/32\n",
      "Scraping https://vsikatalogi.si/akcije/page/33\n",
      "Scraping https://vsikatalogi.si/akcije/page/34\n",
      "Scraping https://vsikatalogi.si/akcije/page/35\n",
      "Scraping https://vsikatalogi.si/akcije/page/36\n",
      "Scraping https://vsikatalogi.si/akcije/page/37\n",
      "Error scraping products/prices from https://vsikatalogi.si/merkur-akcija/merkur-akcija-izberi-svoj-popust-3: could not convert string to float: '1.899.99'\n",
      "Scraping https://vsikatalogi.si/akcije/page/38\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "def extract_products_and_prices(url):\n",
    "    \"\"\"Extract product names and lowest prices from each <br>-separated line in <div class=\"postcontent\">.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        postcontent = soup.find(\"div\", class_=\"postcontent\")\n",
    "        results = []\n",
    "        if postcontent:\n",
    "            # Split by <br> tags robustly\n",
    "            html = postcontent.decode_contents()\n",
    "            # Split on <br>, <br/>, <br />, etc.\n",
    "            lines = re.split(r'<br\\s*/?>', html, flags=re.IGNORECASE)\n",
    "            for line in lines:\n",
    "                text = BeautifulSoup(line, \"html.parser\").get_text().strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                # Find all euro prices in the line\n",
    "                prices = [float(p.replace(\" \", \"\").replace(\",\", \".\"))\n",
    "                          for p in re.findall(r'(\\d[\\d\\s,.]*\\d)\\s*€', text)]\n",
    "                if prices:\n",
    "                    lowest_price = min(prices)\n",
    "                    # Find the first price position to extract product name\n",
    "                    price_match = re.search(r'(\\d[\\d\\s,.]*\\d)\\s*€', text)\n",
    "                    if price_match:\n",
    "                        product_name = text[:price_match.start()].strip(\"–- ,\")\n",
    "                        product_name = product_name[:1].upper() + product_name[1:]\n",
    "                        results.append((lowest_price, product_name))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping products/prices from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://vsikatalogi.si/akcije/page/\"\n",
    "    output_file = \"vsikatalogi_scraped.csv\"\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=\";\")\n",
    "        writer.writerow([\"Title\", \"Date\", \"Price (€)\", \"Product Name\"])\n",
    "        for page_num in range(1, 39):\n",
    "            url = f\"{base_url}{page_num}\"\n",
    "            print(f\"Scraping {url}\")\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "                r.raise_for_status()\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                article_list = soup.find(\"ul\", class_=\"article_list\")\n",
    "                if not article_list:\n",
    "                    continue\n",
    "                for li in article_list.find_all(\"li\"):\n",
    "                    details = li.find(\"div\", class_=\"details\")\n",
    "                    if not details:\n",
    "                        continue\n",
    "                    a_tag = details.find(\"a\", href=True, title=True)\n",
    "                    if not a_tag:\n",
    "                        continue\n",
    "                    link = a_tag[\"href\"]\n",
    "                    title = a_tag[\"title\"].strip()\n",
    "                    # Find date in offer_time\n",
    "                    offer_time = li.find(\"div\", class_=\"offer_time\")\n",
    "                    date = \"\"\n",
    "                    if offer_time:\n",
    "                        strong = offer_time.find(\"strong\", class_=\"dtime\")\n",
    "                        if strong:\n",
    "                            date = strong.get_text(strip=True)\n",
    "                    # Scrape products and prices from the linked page\n",
    "                    products = extract_products_and_prices(link)\n",
    "                    if not products:\n",
    "                        writer.writerow([title, date, \"\", \"\"])\n",
    "                    else:\n",
    "                        for price, product_name in products:\n",
    "                            writer.writerow([title, date, price, product_name])\n",
    "                    time.sleep(0.2)  # Be polite to the server\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "            time.sleep(1)  # Be polite to the server\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a5bf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file written to vsikatalogi_scraped_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"vsikatalogi_scraped.csv\"\n",
    "output_file = \"vsikatalogi_scraped_clean.csv\"\n",
    "\n",
    "# List of known store names (add more as needed)\n",
    "store_names = [\n",
    "    \"E Leclerc\", \"Perutnina Ptuj\", \"Jager\", \"Mass\", \"Mercator\", \"Tuš\", \"Spar\", \"Lidl\", \"Hofer\", \"Eurospin\",\n",
    "    \"DM\", \"Müller\", \"Big Bang\", \"Harvey Norman\", \"Baby Center\", \"Intersport\", \"Hervis\", \"Sport Vision\",\n",
    "    \"OVS\", \"C&A\", \"NKD\", \"Pepco\", \"Kik\", \"Mana\", \"Tedi\"\n",
    "]\n",
    "\n",
    "def clean_store(title):\n",
    "    title_lower = title.lower()\n",
    "    for store in store_names:\n",
    "        if store.lower() in title_lower:\n",
    "            return store\n",
    "    # fallback: first word\n",
    "    return title.split()[0]\n",
    "\n",
    "with open(input_file, newline='', encoding=\"utf-8\") as infile, open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile, delimiter=\";\")\n",
    "    writer = csv.writer(outfile, delimiter=\";\")\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)  # Write header\n",
    "\n",
    "    for row in reader:\n",
    "        if not row or not row[0]:\n",
    "            continue\n",
    "        row[0] = clean_store(row[0])\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Cleaned file written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340d95cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and enriched file written to vsikatalogi_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_date(date_str):\n",
    "    date_str = date_str.strip().replace(\"Do daljnjeg\", \"\")\n",
    "    if not date_str:\n",
    "        return \"\"\n",
    "    # Try common formats\n",
    "    for fmt in (\"%d.%m.%Y.\", \"%d.%m.%Y\", \"%d-%m-%Y\", \"%d.%m.%y\", \"%d-%m-%y\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            continue\n",
    "    # If nothing matches, return original\n",
    "    return date_str\n",
    "\n",
    "def clean_product_name(name):\n",
    "    name = re.sub(r\"\\bredna cena\\b|\\bnamesto\\b|\\bceneje\\b|%|\\bgratis\\b|,\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip().capitalize()\n",
    "\n",
    "def clean_price(price):\n",
    "    try:\n",
    "        return float(price.replace(\",\", \".\"))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "input_file = \"vsikatalogi_scraped_clean.csv\"\n",
    "output_file = \"vsikatalogi_ready.csv\"\n",
    "\n",
    "with open(input_file, newline='', encoding=\"utf-8\") as infile, open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile, delimiter=\";\")\n",
    "    writer = csv.writer(outfile, delimiter=\";\")\n",
    "    header = next(reader)\n",
    "    writer.writerow([\"ID\", \"Store\", \"Date\", \"Price (€)\", \"Product Name\"])\n",
    "    row_id = 1\n",
    "    for row in reader:\n",
    "        if len(row) < 4:\n",
    "            continue\n",
    "        store = row[0].strip().capitalize()\n",
    "        date = clean_date(row[1])\n",
    "        price = clean_price(row[2])\n",
    "        product = clean_product_name(row[3])\n",
    "        # Filter out too long or too short product names, or names containing \"nad\" or \"ob nakupu\"\n",
    "        if not product or product == \"\" or price == \"\":\n",
    "            continue\n",
    "        if len(product) > 80:\n",
    "            continue\n",
    "        pname_lower = product.lower()\n",
    "        if \"nad\" in pname_lower or \"ob nakupu\" in pname_lower or len(product) < 3:\n",
    "            continue\n",
    "        writer.writerow([row_id, store, date, price, product])\n",
    "        row_id += 1\n",
    "\n",
    "print(f\"Cleaned and enriched file written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54eab72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://vsikatalogi.si/vikend-akcije/page/1\n",
      "Error scraping products/prices from https://vsikatalogi.si/mercator-katalog/mercator-vikend-akcija-do-10-5-2: could not convert string to float: '0..99'\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/2\n",
      "Error scraping products/prices from https://vsikatalogi.si/mercator-akcija/mercator-vikend-akcija-do-18-1: could not convert string to float: '1.4.35'\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/3\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/4\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/5\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/6\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/7\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/8\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/9\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/10\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/11\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/12\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/13\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/14\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/15\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/16\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/17\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/18\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/19\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/20\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/21\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/22\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/23\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/24\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/25\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/26\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/27\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/28\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/29\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/30\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/31\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/32\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/33\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/34\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/35\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/36\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/37\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/38\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/39\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     80\u001b[39m             time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strong:\n\u001b[32m     70\u001b[39m         date = strong.get_text(strip=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m products = \u001b[43mextract_products_and_prices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m products:\n\u001b[32m     73\u001b[39m     writer.writerow([title, date, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mextract_products_and_prices\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Extract product names and lowest prices from each <p> in <div class='postcontent'>.\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     r.raise_for_status()\n\u001b[32m     12\u001b[39m     soup = BeautifulSoup(r.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1423\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1425\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "def extract_products_and_prices(url):\n",
    "    \"\"\"Extract product names and lowest prices from each <p> in <div class='postcontent'>.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        postcontent = soup.find(\"div\", class_=\"postcontent\")\n",
    "        results = []\n",
    "        if postcontent:\n",
    "            for p in postcontent.find_all(\"p\"):\n",
    "                text = p.get_text().strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                # Find all euro prices in the line\n",
    "                prices = [float(pr.replace(\" \", \"\").replace(\",\", \".\"))\n",
    "                          for pr in re.findall(r'(\\d[\\d\\s,.]*\\d)\\s*€', text)]\n",
    "                if prices:\n",
    "                    lowest_price = min(prices)\n",
    "                    # Find the first price position to extract product name\n",
    "                    price_match = re.search(r'(\\d[\\d\\s,.]*\\d)\\s*€', text)\n",
    "                    if price_match:\n",
    "                        product_name = text[:price_match.start()].strip(\"–- ,\")\n",
    "                        # Capitalize first letter\n",
    "                        if product_name:\n",
    "                            product_name = product_name[:1].upper() + product_name[1:]\n",
    "                        results.append((lowest_price, product_name))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping products/prices from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://vsikatalogi.si/vikend-akcije/page/\"\n",
    "    output_file = \"vikend_akcije_scraped.csv\"\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=\";\")\n",
    "        writer.writerow([\"Title\", \"Date\", \"Price (€)\", \"Product Name\"])\n",
    "        for page_num in range(1, 54):  # Try just 2 pages for debug\n",
    "            url = f\"{base_url}{page_num}\"\n",
    "            print(f\"Scraping {url}\")\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "                r.raise_for_status()\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                article_list = soup.find(\"ul\", class_=\"article_list\")\n",
    "                if not article_list:\n",
    "                    raise Exception(\"article_list not found\")\n",
    "                for li in article_list.find_all(\"li\"):\n",
    "                    details = li.find(\"div\", class_=\"details\")\n",
    "                    if not details:\n",
    "                        print(\"details not found in li, skipping\")\n",
    "                        continue\n",
    "                    a_tag = details.find(\"a\", href=True, title=True)\n",
    "                    if not a_tag:\n",
    "                        print(\"a_tag not found in details, skipping\")\n",
    "                        continue\n",
    "                    link = a_tag[\"href\"]\n",
    "                    title = a_tag[\"title\"].strip()\n",
    "                    offer_time = li.find(\"div\", class_=\"offer_time\")\n",
    "                    date = \"\"\n",
    "                    if offer_time:\n",
    "                        strong = offer_time.find(\"strong\", class_=\"dtime\")\n",
    "                        if strong:\n",
    "                            date = strong.get_text(strip=True)\n",
    "                    products = extract_products_and_prices(link)\n",
    "                    if not products:\n",
    "                        writer.writerow([title, date, \"\", \"\"])\n",
    "                    else:\n",
    "                        for price, product_name in products:\n",
    "                            writer.writerow([title, date, price, product_name])\n",
    "                    time.sleep(0.2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f12708e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://vsikatalogi.si/vikend-akcije/page/40\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/41\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/42\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/43\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/44\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/45\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/46\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/47\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/48\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/49\n",
      "Scraping https://vsikatalogi.si/vikend-akcije/page/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     80\u001b[39m             time.sleep(\u001b[32m1\u001b[39m)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     r.raise_for_status()\n\u001b[32m     50\u001b[39m     soup = BeautifulSoup(r.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1423\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1425\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "def extract_products_and_prices(url):\n",
    "    \"\"\"Extract product names and lowest prices from each <p> in <div class='postcontent'>.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        postcontent = soup.find(\"div\", class_=\"postcontent\")\n",
    "        results = []\n",
    "        if postcontent:\n",
    "            for p in postcontent.find_all(\"p\"):\n",
    "                text = p.get_text().strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "                # Find all euro prices in the line\n",
    "                prices = [float(pr.replace(\" \", \"\").replace(\",\", \".\"))\n",
    "                          for pr in re.findall(r'(\\d[\\d\\s,.]*\\d)\\s*€', text)]\n",
    "                if prices:\n",
    "                    lowest_price = min(prices)\n",
    "                    # Find the first price position to extract product name\n",
    "                    price_match = re.search(r'(\\d[\\d\\s,.]*\\d)\\s*€', text)\n",
    "                    if price_match:\n",
    "                        product_name = text[:price_match.start()].strip(\"–- ,\")\n",
    "                        # Capitalize first letter\n",
    "                        if product_name:\n",
    "                            product_name = product_name[:1].upper() + product_name[1:]\n",
    "                        results.append((lowest_price, product_name))\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping products/prices from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://vsikatalogi.si/vikend-akcije/page/\"\n",
    "    output_file = \"vikend_akcije_scraped_2del.csv\"\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f, delimiter=\";\")\n",
    "        writer.writerow([\"Title\", \"Date\", \"Price (€)\", \"Product Name\"])\n",
    "        for page_num in range(40, 54):  # Try just 2 pages for debug\n",
    "            url = f\"{base_url}{page_num}\"\n",
    "            print(f\"Scraping {url}\")\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "                r.raise_for_status()\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                article_list = soup.find(\"ul\", class_=\"article_list\")\n",
    "                if not article_list:\n",
    "                    raise Exception(\"article_list not found\")\n",
    "                for li in article_list.find_all(\"li\"):\n",
    "                    details = li.find(\"div\", class_=\"details\")\n",
    "                    if not details:\n",
    "                        print(\"details not found in li, skipping\")\n",
    "                        continue\n",
    "                    a_tag = details.find(\"a\", href=True, title=True)\n",
    "                    if not a_tag:\n",
    "                        print(\"a_tag not found in details, skipping\")\n",
    "                        continue\n",
    "                    link = a_tag[\"href\"]\n",
    "                    title = a_tag[\"title\"].strip()\n",
    "                    offer_time = li.find(\"div\", class_=\"offer_time\")\n",
    "                    date = \"\"\n",
    "                    if offer_time:\n",
    "                        strong = offer_time.find(\"strong\", class_=\"dtime\")\n",
    "                        if strong:\n",
    "                            date = strong.get_text(strip=True)\n",
    "                    products = extract_products_and_prices(link)\n",
    "                    if not products:\n",
    "                        writer.writerow([title, date, \"\", \"\"])\n",
    "                    else:\n",
    "                        for price, product_name in products:\n",
    "                            writer.writerow([title, date, price, product_name])\n",
    "                    time.sleep(0.2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping {url}: {e}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5344087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file written to vikend_akcije_scraped_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"vikend_akcije_scraped.csv\"\n",
    "output_file = \"vikend_akcije_scraped_clean.csv\"\n",
    "\n",
    "# List of known store names (add more as needed)\n",
    "store_names = [\n",
    "    \"E Leclerc\", \"Perutnina Ptuj\", \"Jager\", \"Mass\", \"Mercator\", \"Tuš\", \"Spar\", \"Lidl\", \"Hofer\", \"Eurospin\",\n",
    "    \"DM\", \"Müller\", \"Big Bang\", \"Harvey Norman\", \"Baby Center\", \"Intersport\", \"Hervis\", \"Sport Vision\",\n",
    "    \"OVS\", \"C&A\", \"NKD\", \"Pepco\", \"Kik\", \"Mana\", \"Tedi\"\n",
    "]\n",
    "\n",
    "def clean_store(title):\n",
    "    title_lower = title.lower()\n",
    "    for store in store_names:\n",
    "        if store.lower() in title_lower:\n",
    "            return store\n",
    "    # fallback: first word\n",
    "    return title.split()[0]\n",
    "\n",
    "with open(input_file, newline='', encoding=\"utf-8\") as infile, open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile, delimiter=\";\")\n",
    "    writer = csv.writer(outfile, delimiter=\";\")\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)  # Write header\n",
    "\n",
    "    for row in reader:\n",
    "        if not row or not row[0]:\n",
    "            continue\n",
    "        row[0] = clean_store(row[0])\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Cleaned file written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "894fd7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and enriched file written to vikend_akcije_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_date(date_str):\n",
    "    date_str = date_str.strip().replace(\"Do daljnjeg\", \"\")\n",
    "    if not date_str:\n",
    "        return \"\"\n",
    "    # Try common formats\n",
    "    for fmt in (\"%d.%m.%Y.\", \"%d.%m.%Y\", \"%d-%m-%Y\", \"%d.%m.%y\", \"%d-%m-%y\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            continue\n",
    "    # If nothing matches, return original\n",
    "    return date_str\n",
    "\n",
    "def clean_product_name(name):\n",
    "    name = re.sub(r\"\\bredna cena\\b|\\bnamesto\\b|\\bceneje\\b|%|\\bgratis\\b|,\", \"\", name, flags=re.IGNORECASE)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip().capitalize()\n",
    "\n",
    "def clean_price(price):\n",
    "    try:\n",
    "        return float(price.replace(\",\", \".\"))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "input_file = \"vikend_akcije_scraped_clean.csv\"\n",
    "output_file = \"vikend_akcije_ready.csv\"\n",
    "\n",
    "with open(input_file, newline='', encoding=\"utf-8\") as infile, open(output_file, \"w\", newline='', encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile, delimiter=\";\")\n",
    "    writer = csv.writer(outfile, delimiter=\";\")\n",
    "    header = next(reader)\n",
    "    writer.writerow([\"ID\", \"Store\", \"Date\", \"Price (€)\", \"Product Name\"])\n",
    "    row_id = 1\n",
    "    for row in reader:\n",
    "        if len(row) < 4:\n",
    "            continue\n",
    "        store = row[0].strip().capitalize()\n",
    "        date = clean_date(row[1])\n",
    "        price = clean_price(row[2])\n",
    "        product = clean_product_name(row[3])\n",
    "        # Filter out too long or too short product names, or names containing \"nad\" or \"ob nakupu\"\n",
    "        if not product or product == \"\" or price == \"\":\n",
    "            continue\n",
    "        if len(product) > 80:\n",
    "            continue\n",
    "        pname_lower = product.lower()\n",
    "        if \"nad\" in pname_lower or \"ob nakupu\" in pname_lower or len(product) < 3:\n",
    "            continue\n",
    "        writer.writerow([row_id, store, date, price, product])\n",
    "        row_id += 1\n",
    "\n",
    "print(f\"Cleaned and enriched file written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
